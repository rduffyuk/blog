<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>About | Ryan Duffy - AI Infrastructure &amp; Local LLM Journey</title>
<meta name="keywords" content="">
<meta name="description" content="About This Blog
Hi, I&rsquo;m Ryan Duffy, and this is my digital garden where I document my journey building a production-grade AI infrastructure on consumer hardware.
What I&rsquo;m Building
I run a complete local AI stack on an RTX 4080:

11 local LLM models via Ollama (Mistral, Qwen, DeepSeek)
vLLM server for high-performance inference
Kubernetes observability (Jaeger, OpenTelemetry, Kafka)
ChromaDB semantic search with 504 indexed documents
Automated workflows using Prefect

Why This Blog?
Most AI content is either:">
<meta name="author" content="Ryan Duffy">
<link rel="canonical" href="https://blog.rduffy.uk/about/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css" integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn&#43;yY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://blog.rduffy.uk/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://blog.rduffy.uk/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://blog.rduffy.uk/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://blog.rduffy.uk/apple-touch-icon.png">
<link rel="mask-icon" href="https://blog.rduffy.uk/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://blog.rduffy.uk/about/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="icon" type="image/svg+xml" href="/favicon.svg"><style>
   
  .mermaid-diagram {
    margin: 2.5rem 0;
    padding: 1.5rem;
    background: var(--code-bg);
    border: 1px solid var(--border);
    border-radius: 8px;
    text-align: center;
  }

   
  .mermaid-diagram img {
    max-width: 100%;
    height: auto;
    min-height: 300px;
    display: block;
    margin: 0 auto;
    image-rendering: -webkit-optimize-contrast;
    image-rendering: crisp-edges;
  }

   
  @media (max-width: 768px) {
    .mermaid-diagram {
      padding: 1rem;
      margin: 1.5rem -1rem;
    }
    .mermaid-diagram img {
      min-height: 250px;
    }
  }
</style>
<meta property="og:url" content="https://blog.rduffy.uk/about/">
  <meta property="og:site_name" content="Ryan Duffy - AI Infrastructure & Local LLM Journey">
  <meta property="og:title" content="About">
  <meta property="og:description" content="About This Blog Hi, I’m Ryan Duffy, and this is my digital garden where I document my journey building a production-grade AI infrastructure on consumer hardware.
What I’m Building I run a complete local AI stack on an RTX 4080:
11 local LLM models via Ollama (Mistral, Qwen, DeepSeek) vLLM server for high-performance inference Kubernetes observability (Jaeger, OpenTelemetry, Kafka) ChromaDB semantic search with 504 indexed documents Automated workflows using Prefect Why This Blog? Most AI content is either:">
  <meta property="og:locale" content="en-gb">
  <meta property="og:type" content="article">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="About">
<meta name="twitter:description" content="About This Blog
Hi, I&rsquo;m Ryan Duffy, and this is my digital garden where I document my journey building a production-grade AI infrastructure on consumer hardware.
What I&rsquo;m Building
I run a complete local AI stack on an RTX 4080:

11 local LLM models via Ollama (Mistral, Qwen, DeepSeek)
vLLM server for high-performance inference
Kubernetes observability (Jaeger, OpenTelemetry, Kafka)
ChromaDB semantic search with 504 indexed documents
Automated workflows using Prefect

Why This Blog?
Most AI content is either:">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "About",
      "item": "https://blog.rduffy.uk/about/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "About",
  "name": "About",
  "description": "About This Blog Hi, I\u0026rsquo;m Ryan Duffy, and this is my digital garden where I document my journey building a production-grade AI infrastructure on consumer hardware.\nWhat I\u0026rsquo;m Building I run a complete local AI stack on an RTX 4080:\n11 local LLM models via Ollama (Mistral, Qwen, DeepSeek) vLLM server for high-performance inference Kubernetes observability (Jaeger, OpenTelemetry, Kafka) ChromaDB semantic search with 504 indexed documents Automated workflows using Prefect Why This Blog? Most AI content is either:\n",
  "keywords": [
    
  ],
  "articleBody": "About This Blog Hi, I’m Ryan Duffy, and this is my digital garden where I document my journey building a production-grade AI infrastructure on consumer hardware.\nWhat I’m Building I run a complete local AI stack on an RTX 4080:\n11 local LLM models via Ollama (Mistral, Qwen, DeepSeek) vLLM server for high-performance inference Kubernetes observability (Jaeger, OpenTelemetry, Kafka) ChromaDB semantic search with 504 indexed documents Automated workflows using Prefect Why This Blog? Most AI content is either:\nTheoretical tutorials that don’t show real performance Enterprise solutions requiring $10k/month budgets Hobby projects that don’t scale I’m bridging the gap - showing how to build professional AI infrastructure on a £1,500 GPU that delivers production-quality results.\nWhat You’ll Learn Real benchmarks: Actual tokens/sec, VRAM usage, latency measurements Configuration deep-dives: The settings that actually matter Automation patterns: How to build systems that maintain themselves Cost optimization: Getting $0/month inference with enterprise quality My Stack Hardware: RTX 4080 (16GB), i9-13900KF, 62GB RAM Software: Ubuntu 22.04, K3s, Ollama 0.12.3, vLLM, PyTorch Workflow: Obsidian vault → Prefect automation → ChromaDB indexing Philosophy: Local-first, automation-driven, measurably fast\nCurrent Projects ConvoCanvas (Season 1 - September 2025) A system that transforms AI conversations into publishable content:\nAutomatically extracts insights from Claude/ChatGPT conversations Organizes knowledge into searchable Obsidian vault structure Generates blog posts with embedded Mermaid diagrams Status: Publishing Season 1 (8 episodes covering 25-day journey) Neural Vault Semantic search across 1000+ documentation files:\nChromaDB indexing with mxbai-embed-large embeddings Dual-layer caching (gather + action phases) MCP integration for Claude Code Sub-second search with smart routing K3s Observability Stack Full distributed tracing on single-node cluster:\nJaeger + OpenTelemetry for request tracing Kafka streaming pipeline Prometheus + Grafana metrics MongoDB with Percona operator What Are “Tags” on This Blog? Tags are topic labels that help you explore related content. Each tag represents a technology, concept, or project I’m working with.\nHow to use tags:\nClick any tag on a blog post (e.g., #Ollama, #ChromaDB) See all posts related to that topic Follow my journey with specific technologies chronologically Popular tags:\n#ConvoCanvas - Automated blog publishing project #Ollama - Local LLM inference #K3s - Kubernetes observability #ChromaDB - Semantic search #vLLM - High-performance LLM serving Tags let you skip the chronological timeline and dive straight into topics you care about.\nConnect GitHub: github.com/rduffyuk - Public code \u0026 configs RSS: Subscribe to feed - New posts delivered weekly Philosophy Build \u003e Buy: If it can run locally, I’ll make it work Document \u003e Ship: Learning in public beats silent shipping Honest \u003e Impressive: Real limitations beat fake unlimited claims\nLast updated: October 5, 2025 Generated with Hugo + PaperMod | Hosted on GitHub Pages | Written in Obsidian\n",
  "wordCount" : "445",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Ryan Duffy"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://blog.rduffy.uk/about/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Ryan Duffy - AI Infrastructure \u0026 Local LLM Journey",
    "logo": {
      "@type": "ImageObject",
      "url": "https://blog.rduffy.uk/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://blog.rduffy.uk/" accesskey="h" title="Ryan Duffy - AI Infrastructure &amp; Local LLM Journey (Alt + H)">Ryan Duffy - AI Infrastructure &amp; Local LLM Journey</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://blog.rduffy.uk/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://blog.rduffy.uk/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://blog.rduffy.uk/about/" title="About">
                    <span class="active">About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      About
    </h1>
    <div class="post-meta"><span>Ryan Duffy</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#what-im-building">What I&rsquo;m Building</a></li>
    <li><a href="#why-this-blog">Why This Blog?</a></li>
    <li><a href="#what-youll-learn">What You&rsquo;ll Learn</a></li>
    <li><a href="#my-stack">My Stack</a></li>
    <li><a href="#current-projects">Current Projects</a>
      <ul>
        <li><a href="#convocanvas-season-1---september-2025">ConvoCanvas (Season 1 - September 2025)</a></li>
        <li><a href="#neural-vault">Neural Vault</a></li>
        <li><a href="#k3s-observability-stack">K3s Observability Stack</a></li>
      </ul>
    </li>
    <li><a href="#what-are-tags-on-this-blog">What Are &ldquo;Tags&rdquo; on This Blog?</a></li>
    <li><a href="#connect">Connect</a></li>
    <li><a href="#philosophy">Philosophy</a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="about-this-blog">About This Blog<a hidden class="anchor" aria-hidden="true" href="#about-this-blog">#</a></h1>
<p>Hi, I&rsquo;m <strong>Ryan Duffy</strong>, and this is my digital garden where I document my journey building a production-grade AI infrastructure on consumer hardware.</p>
<h2 id="what-im-building">What I&rsquo;m Building<a hidden class="anchor" aria-hidden="true" href="#what-im-building">#</a></h2>
<p>I run a complete local AI stack on an RTX 4080:</p>
<ul>
<li><strong>11 local LLM models</strong> via Ollama (Mistral, Qwen, DeepSeek)</li>
<li><strong>vLLM server</strong> for high-performance inference</li>
<li><strong>Kubernetes observability</strong> (Jaeger, OpenTelemetry, Kafka)</li>
<li><strong>ChromaDB semantic search</strong> with 504 indexed documents</li>
<li><strong>Automated workflows</strong> using Prefect</li>
</ul>
<h2 id="why-this-blog">Why This Blog?<a hidden class="anchor" aria-hidden="true" href="#why-this-blog">#</a></h2>
<p>Most AI content is either:</p>
<ul>
<li>Theoretical tutorials that don&rsquo;t show real performance</li>
<li>Enterprise solutions requiring $10k/month budgets</li>
<li>Hobby projects that don&rsquo;t scale</li>
</ul>
<p><strong>I&rsquo;m bridging the gap</strong> - showing how to build professional AI infrastructure on a £1,500 GPU that delivers production-quality results.</p>
<h2 id="what-youll-learn">What You&rsquo;ll Learn<a hidden class="anchor" aria-hidden="true" href="#what-youll-learn">#</a></h2>
<ul>
<li><strong>Real benchmarks</strong>: Actual tokens/sec, VRAM usage, latency measurements</li>
<li><strong>Configuration deep-dives</strong>: The settings that actually matter</li>
<li><strong>Automation patterns</strong>: How to build systems that maintain themselves</li>
<li><strong>Cost optimization</strong>: Getting $0/month inference with enterprise quality</li>
</ul>
<h2 id="my-stack">My Stack<a hidden class="anchor" aria-hidden="true" href="#my-stack">#</a></h2>
<p><strong>Hardware</strong>: RTX 4080 (16GB), i9-13900KF, 62GB RAM
<strong>Software</strong>: Ubuntu 22.04, K3s, Ollama 0.12.3, vLLM, PyTorch
<strong>Workflow</strong>: Obsidian vault → Prefect automation → ChromaDB indexing
<strong>Philosophy</strong>: Local-first, automation-driven, measurably fast</p>
<h2 id="current-projects">Current Projects<a hidden class="anchor" aria-hidden="true" href="#current-projects">#</a></h2>
<h3 id="convocanvas-season-1---september-2025">ConvoCanvas (Season 1 - September 2025)<a hidden class="anchor" aria-hidden="true" href="#convocanvas-season-1---september-2025">#</a></h3>
<p>A system that transforms AI conversations into publishable content:</p>
<ul>
<li>Automatically extracts insights from Claude/ChatGPT conversations</li>
<li>Organizes knowledge into searchable Obsidian vault structure</li>
<li>Generates blog posts with embedded Mermaid diagrams</li>
<li><strong>Status</strong>: Publishing Season 1 (8 episodes covering 25-day journey)</li>
</ul>
<h3 id="neural-vault">Neural Vault<a hidden class="anchor" aria-hidden="true" href="#neural-vault">#</a></h3>
<p>Semantic search across 1000+ documentation files:</p>
<ul>
<li>ChromaDB indexing with mxbai-embed-large embeddings</li>
<li>Dual-layer caching (gather + action phases)</li>
<li>MCP integration for Claude Code</li>
<li>Sub-second search with smart routing</li>
</ul>
<h3 id="k3s-observability-stack">K3s Observability Stack<a hidden class="anchor" aria-hidden="true" href="#k3s-observability-stack">#</a></h3>
<p>Full distributed tracing on single-node cluster:</p>
<ul>
<li>Jaeger + OpenTelemetry for request tracing</li>
<li>Kafka streaming pipeline</li>
<li>Prometheus + Grafana metrics</li>
<li>MongoDB with Percona operator</li>
</ul>
<h2 id="what-are-tags-on-this-blog">What Are &ldquo;Tags&rdquo; on This Blog?<a hidden class="anchor" aria-hidden="true" href="#what-are-tags-on-this-blog">#</a></h2>
<p><strong>Tags are topic labels</strong> that help you explore related content. Each tag represents a technology, concept, or project I&rsquo;m working with.</p>
<p><strong>How to use tags</strong>:</p>
<ul>
<li>Click any tag on a blog post (e.g., <a href="/tags/ollama/">#Ollama</a>, <a href="/tags/chromadb/">#ChromaDB</a>)</li>
<li>See all posts related to that topic</li>
<li>Follow my journey with specific technologies chronologically</li>
</ul>
<p><strong>Popular tags</strong>:</p>
<ul>
<li><a href="/tags/convocanvas/">#ConvoCanvas</a> - Automated blog publishing project</li>
<li><a href="/tags/ollama/">#Ollama</a> - Local LLM inference</li>
<li><a href="/tags/k3s/">#K3s</a> - Kubernetes observability</li>
<li><a href="/tags/chromadb/">#ChromaDB</a> - Semantic search</li>
<li><a href="/tags/vllm/">#vLLM</a> - High-performance LLM serving</li>
</ul>
<p>Tags let you <strong>skip the chronological timeline</strong> and dive straight into topics you care about.</p>
<h2 id="connect">Connect<a hidden class="anchor" aria-hidden="true" href="#connect">#</a></h2>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/rduffyuk">github.com/rduffyuk</a> - Public code &amp; configs</li>
<li><strong>RSS</strong>: <a href="/index.xml">Subscribe to feed</a> - New posts delivered weekly</li>
</ul>
<h2 id="philosophy">Philosophy<a hidden class="anchor" aria-hidden="true" href="#philosophy">#</a></h2>
<p><strong>Build &gt; Buy</strong>: If it can run locally, I&rsquo;ll make it work
<strong>Document &gt; Ship</strong>: Learning in public beats silent shipping
<strong>Honest &gt; Impressive</strong>: Real limitations beat fake unlimited claims</p>
<hr>
<p><em>Last updated: October 5, 2025</em>
<em>Generated with Hugo + PaperMod | Hosted on GitHub Pages | Written in Obsidian</em></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://blog.rduffy.uk/">Ryan Duffy - AI Infrastructure &amp; Local LLM Journey</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
